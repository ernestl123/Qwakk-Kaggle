{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c41c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (4.61.2)\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7cd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873099af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c70c017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>LEN</th>\n",
       "      <th>MON</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HR</th>\n",
       "      <th>WK</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>DAY_TYPE_A</th>\n",
       "      <th>DAY_TYPE_B</th>\n",
       "      <th>DAY_TYPE_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>330</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>270</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "      <td>960</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>630</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>420</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              TRIP_ID  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "0           0  1372636858620000589          0.0           0.0  20000589   \n",
       "1           1  1372637303620000596          0.0           7.0  20000596   \n",
       "2           2  1372636951620000320          0.0           0.0  20000320   \n",
       "3           3  1372636854620000520          0.0           0.0  20000520   \n",
       "4           4  1372637091620000337          0.0           0.0  20000337   \n",
       "\n",
       "    TIMESTAMP                                           POLYLINE  LEN  MON  \\\n",
       "0  1372636858  [[-8.618643,41.141412],[-8.618499,41.141376],[...  330    7   \n",
       "1  1372637303  [[-8.639847,41.159826],[-8.640351,41.159871],[...  270    7   \n",
       "2  1372636951  [[-8.612964,41.140359],[-8.613378,41.14035],[-...  960    7   \n",
       "3  1372636854  [[-8.574678,41.151951],[-8.574705,41.151942],[...  630    7   \n",
       "4  1372637091  [[-8.645994,41.18049],[-8.645949,41.180517],[-...  420    7   \n",
       "\n",
       "   DAY  HR  WK  CALL_TYPE_A  CALL_TYPE_B  CALL_TYPE_C  DAY_TYPE_A  DAY_TYPE_B  \\\n",
       "0    1   0   0            0            0            1           1           0   \n",
       "1    1   0   0            0            1            0           1           0   \n",
       "2    1   0   0            0            0            1           1           0   \n",
       "3    1   0   0            0            0            1           1           0   \n",
       "4    1   0   0            0            0            1           1           0   \n",
       "\n",
       "   DAY_TYPE_C  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6425c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing these for this MLP model only\n",
    "#df = df.drop(columns=[\"Unnamed: 0\", \"TRIP_ID\", \"ORIGIN_CALL\", \"TAXI_ID\", \"TIMESTAMP\", \"POLYLINE\"])\n",
    "df = df.drop(columns=[\"Unnamed: 0\", \"TRIP_ID\", \"ORIGIN_CALL\", \"ORIGIN_STAND\", \"TAXI_ID\", \"TIMESTAMP\"])\n",
    "#df = df.drop(columns=[\"Unnamed: 0\", \"ORIGIN_CALL\", \"ORIGIN_STAND\", \"TAXI_ID\", \"TIMESTAMP\", \"YR_2014\", \"YR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2f73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df#.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dacd3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_len = df[\"LEN\"]\n",
    "df_sample = df_sample.drop(columns=[\"LEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e3cfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855330"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9929e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>MON</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HR</th>\n",
       "      <th>WK</th>\n",
       "      <th>CALL_TYPE_A</th>\n",
       "      <th>CALL_TYPE_B</th>\n",
       "      <th>CALL_TYPE_C</th>\n",
       "      <th>DAY_TYPE_A</th>\n",
       "      <th>DAY_TYPE_B</th>\n",
       "      <th>DAY_TYPE_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1425543</th>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080244</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481169</th>\n",
       "      <td>21.0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826555</th>\n",
       "      <td>36.0</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637544</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ORIGIN_STAND  MON  DAY  HR  WK  CALL_TYPE_A  CALL_TYPE_B  \\\n",
       "1425543          57.0    5    6   8   1            0            1   \n",
       "1080244          15.0    2   21   0   4            0            1   \n",
       "481169           21.0   10   12  20   5            0            1   \n",
       "826555           36.0   12   24  11   1            0            1   \n",
       "1637544          10.0    6   16  12   0            0            1   \n",
       "\n",
       "         CALL_TYPE_C  DAY_TYPE_A  DAY_TYPE_B  DAY_TYPE_C  \n",
       "1425543            0           1           0           0  \n",
       "1080244            0           1           0           0  \n",
       "481169             0           1           0           0  \n",
       "826555             0           1           0           0  \n",
       "1637544            0           1           0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5616fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [df_sample.iloc[i].values for i in range(len(df_sample))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73000dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.array(features), dtype = torch.float).to(device)\n",
    "y = torch.tensor(np.array(df_len.values), dtype = torch.float).to(device)\n",
    "\n",
    "data = list(zip(x, y))\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data, test_data, val_data = torch.utils.data.random_split(data, [train_size, test_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ff4d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle = False)\n",
    "# train_loader = train_data\n",
    "# valid_loader = val_data\n",
    "# test_loader = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4265b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684264, 85533, 85533)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3184752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bce3d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    #torch.nn.Embedding(11, 11),\n",
    "    torch.nn.Linear(11, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d1de775",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss().to(device)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3846c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def train_epoch(train_data, model, optimizer, loss_fn, batch_size):\n",
    "    losses = []\n",
    "    train_len = len(train_data)\n",
    "\n",
    "    # get a batch of training data\n",
    "    for x, y in tqdm(train_data):\n",
    "        # make predictions for this batch\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # Compute the RSME loss\n",
    "        loss = torch.sqrt(loss_fn(y_pred, y))\n",
    "        \n",
    "        # Backpropagation\n",
    "        # zero out the gradients so that it will not accumulate through each iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute the gradents with the backward call (backprop)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weight using gradient descent \n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "def eval_epoch(valid_loader, model, loss_function):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    losses = []\n",
    "    with torch.no_grad(): \n",
    "        for x, y in tqdm(valid_loader):\n",
    "            # Compute prediction\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = torch.sqrt(loss_fn(y_pred, y))\n",
    "            losses.append(loss.item())\n",
    "#             total += 1\n",
    "#             correct += ((y <= t+10) and (y >= t-10))\n",
    "#             #trues.append(t)\n",
    "#             preds.append(y)\n",
    "            \n",
    "    return np.mean(losses)#float(correct/total*100), preds\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55d5e352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 684264 data with batch size of 5!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/136853 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8923/4245213437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gradient tracking is on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8923/3216150071.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_data, model, optimizer, loss_fn, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# make predictions for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Compute the RSME loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "total_epochs = 5\n",
    "train_accs, valid_accs = [], []\n",
    "max_acc = 0\n",
    "val_loss = 0\n",
    "print(f\"Training on {len(train_data)} data with batch size of {batch_size}!\")\n",
    "for epoch in range(total_epochs):\n",
    "    \n",
    "    model.train() # gradient tracking is on\n",
    "    \n",
    "    train_loss = train_epoch(train_loader, model, optimizer, loss_fn, batch_size)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = eval_epoch(valid_loader, model, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:>0.4f}, Validation Loss {val_loss:>0.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "eval_epoch(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca158a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "e = len(train_losses)\n",
    "x_axis = np.arange(1, e + 1, 1)\n",
    "plt.plot(x_axis, train_losses, label = \"Train\")\n",
    "plt.plot(x_axis, val_losses, label = \"Validation\")\n",
    "plt.legend()\n",
    "plt.title('Training losses')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768d285",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f51831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# loss_dict = {}\n",
    "# with torch.no_grad(): \n",
    "#     for index, row in df_sample.iterrows():\n",
    "#         x = torch.tensor(row.values, dtype=torch.float).to(device)\n",
    "#         y_pred = model(x)\n",
    "\n",
    "#         loss = torch.sqrt(loss_fn(y_pred, y[count]))\n",
    "#         count += 1\n",
    "\n",
    "#         loss_dict[index] = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c305043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes = list(sorted(loss_dict))\n",
    "# indexes[-11:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce69110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"MLP3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48e93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"processed_test.csv\")\n",
    "df_out = df_test[\"TRIP_ID\"].to_frame()\n",
    "df_test = df_test.drop(columns=[\"Unnamed: 0\", \"TRIP_ID\", \"ORIGIN_CALL\", \"ORIGIN_STAND\", \"TAXI_ID\", \"TIMESTAMP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3b465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [torch.tensor(df_test.iloc[i].values,dtype=torch.float).to(device) for i in range(len(df_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    df_out[\"TRAVEL_TIME\"] = [float(model(x).cpu()) for x in x_test]\n",
    "df_out.head()\n",
    "# # mean(716.43) -> 792.73593\n",
    "# # median(600) -> 784.74219\n",
    "df_out.to_csv(\"my_pred.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Implement accuracy or smthing for training\n",
    "#Do something with validation (make a validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e4175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cec29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
